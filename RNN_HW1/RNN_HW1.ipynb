{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wT8VhfiBHkmz0XhE1KCCFbdnh7Z0G4Ij","authorship_tag":"ABX9TyPaDAt+hTosy85gZoyECvzs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"15030fd625d5437cbba78b0d752e5fcc":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_ae6b244fe2f24bd2976a1da9a0660223","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 1/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:23\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 1/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:23</span>\n</pre>\n"},"metadata":{}}]}},"ae6b244fe2f24bd2976a1da9a0660223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70b46b0d6a2a459d9320b40215830efb":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_018e15cee8c6429c8ebb1e5ca0bde888","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"018e15cee8c6429c8ebb1e5ca0bde888":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8256720ed6341758ca4d30bca6ff91b":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_7a70e4fb2eb64e8b9926a38af5a04e70","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 2/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:26\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 2/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:26</span>\n</pre>\n"},"metadata":{}}]}},"7a70e4fb2eb64e8b9926a38af5a04e70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58c3ce9991204d7fba026a70a7115450":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_9923578eaa9443f68adfaaaa22ce829d","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:43\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n"},"metadata":{}}]}},"9923578eaa9443f68adfaaaa22ce829d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234ab95283474570b06d9f390219e881":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_451cf0ebb10145cfb995fe247fc9668e","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 3/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:24\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 3/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:24</span>\n</pre>\n"},"metadata":{}}]}},"451cf0ebb10145cfb995fe247fc9668e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d1c2cff0b514404b35ff359f404f336":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_3b3d1619bdf04fa4ba26dea4a3575e15","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:43\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n"},"metadata":{}}]}},"3b3d1619bdf04fa4ba26dea4a3575e15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"332e4c57c115439e888d6b1662b1022a":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_8d37d9a377a84f74a4ef3bb0e1e77114","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 4/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:24\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 4/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:24</span>\n</pre>\n"},"metadata":{}}]}},"8d37d9a377a84f74a4ef3bb0e1e77114":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a758f0e3bfc4edcbbb93f94f8e1dcd8":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_b346499704a7429da4b7e1190744b104","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"b346499704a7429da4b7e1190744b104":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5fc57bb2bd7a4ad8abd7f5e8e78fb610":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_3ddb6ccc8ff84acf838f1b3bfe82d2e4","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 5/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:23\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 5/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:23</span>\n</pre>\n"},"metadata":{}}]}},"3ddb6ccc8ff84acf838f1b3bfe82d2e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4ec94d713d244977a802421855deee1a":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_1163bfcf863e44f39ba0d48c02644bf2","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:43\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n"},"metadata":{}}]}},"1163bfcf863e44f39ba0d48c02644bf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a745cadb8c943ed93303683432cbc92":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_e63a2f47610b4e269095f8a0e501d2d9","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 6/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:24\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 6/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:24</span>\n</pre>\n"},"metadata":{}}]}},"e63a2f47610b4e269095f8a0e501d2d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67a262e6c3064aa386abb94f6d9c752c":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_d3d40f1d74924b8fa0754dfbaa59d6f2","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:43\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n"},"metadata":{}}]}},"d3d40f1d74924b8fa0754dfbaa59d6f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bbba8f137ce344bbaf90c63407c56dda":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_321848a8647941fba496ca5668082430","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 7/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:24\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 7/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:24</span>\n</pre>\n"},"metadata":{}}]}},"321848a8647941fba496ca5668082430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c9b6743f5c3f4c519810e530ff0162ea":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_0337c9dc53484cc4bd7679f9d0862cf3","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"0337c9dc53484cc4bd7679f9d0862cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d319f2a9195744feb364214e61a33c1a":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_bdc2c55e9cbe4a439e31e6d623c4069e","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 8/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:23\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 8/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:23</span>\n</pre>\n"},"metadata":{}}]}},"bdc2c55e9cbe4a439e31e6d623c4069e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f242125c31a040009483068e63f0c6df":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_42cacd68d47c42f5bcf52052511447f5","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:43\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:43</span>\n</pre>\n"},"metadata":{}}]}},"42cacd68d47c42f5bcf52052511447f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1fe5cbcb4fa4d7eac324b59e4523e80":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_7d3d6120eba34b97a72d9b8ede0c2d03","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 9/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:23\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 9/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:23</span>\n</pre>\n"},"metadata":{}}]}},"7d3d6120eba34b97a72d9b8ede0c2d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c224b0f4aa224fdeac17981fb944bcee":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_17e15883f86d4d599c0c5eac9f64ba51","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"17e15883f86d4d599c0c5eac9f64ba51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b24e38a944949fa908c2d2c706334b3":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_f5e4928070bd4d81ba241c64d60fd93d","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 10/50\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:08:22\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 10/50</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:08:22</span>\n</pre>\n"},"metadata":{}}]}},"f5e4928070bd4d81ba241c64d60fd93d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d28929bc1f9c4eec8c3c07b13216e574":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_ca523895b8f44e1cb6e0f49697f11334","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;33mValidation\u001b[0m \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">Validation</span> <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #808000; text-decoration-color: #808000\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"ca523895b8f44e1cb6e0f49697f11334":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7418e1c569cb4dac90c085c18c3be526":{"model_module":"@jupyter-widgets/output","model_name":"OutputModel","model_module_version":"1.0.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/output","_model_module_version":"1.0.0","_model_name":"OutputModel","_view_count":null,"_view_module":"@jupyter-widgets/output","_view_module_version":"1.0.0","_view_name":"OutputView","layout":"IPY_MODEL_5e9466de8b674b80a861e1421258182e","msg_id":"","outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;36mEpoch 11/50\u001b[0m \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[35m 92%\u001b[0m \u001b[36m0:00:44\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Epoch 11/50</span> <span style=\"color: #f92672; text-decoration-color: #f92672\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\"> 92%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:44</span>\n</pre>\n"},"metadata":{}}]}},"5e9466de8b674b80a861e1421258182e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"cells":[{"cell_type":"markdown","source":["# **DataProcess**"],"metadata":{"id":"5CtnFfRcMqvh"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pof0s6hrf6OK","executionInfo":{"status":"ok","timestamp":1743849017116,"user_tz":-480,"elapsed":11266,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}},"outputId":"4bd8aae4-22f8-4932-b54b-ffac00af9128"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","import csv"],"metadata":{"id":"Uwh5A8DkNZ7U","executionInfo":{"status":"ok","timestamp":1743849059561,"user_tz":-480,"elapsed":4641,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"K_p6uRogMaLU","executionInfo":{"status":"ok","timestamp":1743849059572,"user_tz":-480,"elapsed":4,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"outputs":[],"source":["def tokenizer(text):\n","    # Split the text into words based on whitespace\n","    return text.split()\n","\n","def numericalize(text, vocab):\n","    # Convert text into a list of numbers according to the given vocabulary.\n","    # If a word is not in the vocabulary, the '<unk>' token index is used.\n","    return [vocab.get(word, vocab['<unk>']) for word in tokenizer(text)]\n","\n","def pad_collate_fn(batch, pad_idx):\n","    # Custom collate function to pad sequences in a batch to the same length.\n","    texts, labels = zip(*batch)\n","    text_lens = [len(text) for text in texts]\n","    max_len = max(text_lens)\n","    # Create a tensor filled with pad index values.\n","    padded_texts = torch.full((len(texts), max_len), pad_idx, dtype=torch.long)\n","    for i, text in enumerate(texts):\n","        padded_texts[i, :text_lens[i]] = text\n","    return padded_texts, torch.tensor(labels, dtype=torch.float)\n","\n","class TextDataset(Dataset):\n","    def __init__(self, texts, labels, vocab):\n","        # Initialize dataset with texts, labels and vocabulary\n","        self.texts = texts\n","        self.labels = labels\n","        self.vocab = vocab\n","\n","    def __len__(self):\n","        # Return the total number of samples in the dataset\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        # Retrieve the numericalized text and corresponding label for a given index\n","        text = numericalize(self.texts[idx], self.vocab)\n","        label = self.labels[idx]\n","        return torch.tensor(text), torch.tensor(label, dtype=torch.float)"]},{"cell_type":"code","source":["class DataLoaderFactory():\n","    def __init__(self, csv_path, text_col='text', label_col='generated',\n","                 train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, random_state=42,\n","                 batch_size_train=32, batch_size_val=32, batch_size_test=1):\n","        # Initialize factory with file path and various ratios for training, validation, and test sets.\n","        self.csv_path = csv_path\n","        self.text_col = text_col\n","        self.label_col = label_col\n","\n","        # Check if the sum of ratios for train, validation, and test equals 1\n","        if abs(train_ratio + val_ratio + test_ratio - 1.0) > 1e-5:\n","            raise ValueError(\"Train, validation and test ratios must sum to 1.0\")\n","\n","        self.train_ratio = train_ratio\n","        self.val_ratio = val_ratio\n","        self.test_ratio = test_ratio\n","        self.random_state = random_state\n","        self.batch_size_train = batch_size_train\n","        self.batch_size_val = batch_size_val\n","        self.batch_size_test = batch_size_test\n","\n","        self.vocab = None\n","        self.train_loader = None\n","        self.val_loader = None\n","        self.test_loader = None\n","\n","        # Prepare data and create dataloaders\n","        self._prepare_data()\n","\n","    def _build_vocab(self, texts):\n","        # Build a vocabulary from the texts using a Counter to count word frequencies.\n","        counter = Counter()\n","        for text in texts:\n","            counter.update(tokenizer(text))\n","        # Create vocabulary mapping starting from index 2\n","        # (reserve index 0 for <unk> and index 1 for <pad>)\n","        vocab = {word: i+2 for i, (word, _) in enumerate(counter.items())}\n","        vocab['<unk>'] = 0\n","        vocab['<pad>'] = 1\n","        return vocab\n","\n","    def _prepare_data(self):\n","        # Read the dataset from the CSV file.\n","        df = pd.read_csv(self.csv_path)\n","        texts = df[self.text_col].tolist()\n","        labels = df[self.label_col].tolist()\n","\n","        # Build vocabulary from all texts.\n","        self.vocab = self._build_vocab(texts)\n","\n","        # Split dataset into training and combined validation+test sets.\n","        texts_train, texts_val_test, labels_train, labels_val_test = train_test_split(\n","            texts, labels, test_size=self.test_ratio+self.val_ratio, random_state=self.random_state)\n","\n","        # Split combined set into validation and test sets.\n","        texts_val, texts_test, labels_val, labels_test = train_test_split(\n","            texts_val_test, labels_val_test, test_size=self.test_ratio/(self.test_ratio+self.val_ratio), random_state=self.random_state)\n","\n","        # Create TextDataset objects for training, validation, and test sets.\n","        train_dataset = TextDataset(texts_train, labels_train, self.vocab)\n","        val_dataset = TextDataset(texts_val, labels_val, self.vocab)\n","        test_dataset = TextDataset(texts_test, labels_test, self.vocab)\n","\n","        # Create DataLoaders for each split.\n","        self.train_loader = DataLoader(\n","            train_dataset,\n","            batch_size=self.batch_size_train,\n","            shuffle=True,\n","            collate_fn=lambda batch: pad_collate_fn(batch, self.vocab['<pad>'])\n","        )\n","        self.val_loader = DataLoader(\n","            val_dataset,\n","            batch_size=self.batch_size_val,\n","            shuffle=False,\n","            collate_fn=lambda batch: pad_collate_fn(batch, self.vocab['<pad>'])\n","        )\n","        self.test_loader = DataLoader(\n","            test_dataset,\n","            batch_size=self.batch_size_test,\n","            shuffle=False,\n","            collate_fn=lambda batch: pad_collate_fn(batch, self.vocab['<pad>'])\n","        )\n","\n","    def get_loaders(self):\n","        # Return the training, validation, and test dataloaders.\n","        return self.train_loader, self.val_loader, self.test_loader"],"metadata":{"id":"S0w86YGsRNfT","executionInfo":{"status":"ok","timestamp":1743849063867,"user_tz":-480,"elapsed":18,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["    csv_file = '/content/drive/MyDrive/RNN_HW1/AI_Human.csv'\n","    # Initialize DataLoaderFactory with the CSV file path and split ratios.\n","    data_factory = DataLoaderFactory(csv_file, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15)\n","    train_loader, val_loader, test_loader = data_factory.get_loaders()\n","\n","    # Print number of batches for each loader as a check.\n","    print(f\"Train loader: {len(train_loader)} batches\")\n","    print(f\"Validation loader: {len(val_loader)} batches\")\n","    print(f\"Test loader: {len(test_loader)} batches\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0J-zjSybRMPY","executionInfo":{"status":"ok","timestamp":1743849184194,"user_tz":-480,"elapsed":63750,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}},"outputId":"48337397-9b9f-4203-cf5d-d612ba93f5ed"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Train loader: 10659 batches\n","Validation loader: 2284 batches\n","Test loader: 73086 batches\n"]}]},{"cell_type":"markdown","source":["# **LSTM Train**"],"metadata":{"id":"gu2uR7CENfF6"}},{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from rich.progress import track\n","from torch.utils.tensorboard import SummaryWriter\n","import argparse"],"metadata":{"id":"5Qs-y73yNihw","executionInfo":{"status":"ok","timestamp":1743849194734,"user_tz":-480,"elapsed":4367,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**LSTMClassifier**"],"metadata":{"id":"BAtrvcHrNm5R"}},{"cell_type":"code","source":["class LSTMClassifier(nn.Module):\n","    \"\"\"\n","    # This LSTMClassifier uses an embedding layer followed by a multi-layer LSTM for text classification.\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx, num_layers=1):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers)\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, text):\n","        # Check if sequence length is zero and return zeros if so.\n","        if text.size(1) == 0:\n","            return torch.zeros(text.size(0), self.fc.out_features, device=text.device)\n","        # Convert input word indices to embeddings\n","        embedded = self.embedding(text)\n","        # Process embeddings through LSTM\n","        _, (hidden, _) = self.lstm(embedded)\n","        # Use the last hidden state for classification\n","        return self.fc(hidden[-1])"],"metadata":{"id":"JvpafUZUNkTl","executionInfo":{"status":"ok","timestamp":1743849194737,"user_tz":-480,"elapsed":1,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**ConvLSTMClassifier**"],"metadata":{"id":"IAX368vwNsED"}},{"cell_type":"code","source":["class ConvLSTMClassifier(nn.Module):\n","    \"\"\"\n","    The ConvLSTMClassifier combines a convolutional layer with an LSTM for text classification.\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx, num_layers=1):\n","        super().__init__()\n","        # Create an embedding layer to convert word indices to dense vectors.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n","        # Create a 1D convolutional layer to capture local features from embeddings.\n","        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=embedding_dim, kernel_size=3, padding=1)\n","        # Create an LSTM layer to capture sequential dependencies.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True)\n","        # Final linear layer to produce the output logits.\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, text):\n","        # Handle empty texts by returning zeros output.\n","        if text.size(1) == 0:\n","            return torch.zeros(text.size(0), self.fc.out_features, device=text.device)\n","        # Obtain word embeddings: shape [batch_size, seq_length, embedding_dim]\n","        embedded = self.embedding(text)\n","        # Rearrange dimensions for Conv1d: from [batch_size, seq_length, embedding_dim]\n","        # to [batch_size, embedding_dim, seq_length]\n","        conv_input = embedded.permute(0, 2, 1)\n","        # Apply convolution followed by ReLU activation: shape remains [batch_size, embedding_dim, seq_length]\n","        conv_out = torch.relu(self.conv(conv_input))\n","        # Rearrange back to LSTM input shape: [batch_size, seq_length, embedding_dim]\n","        conv_out = conv_out.permute(0, 2, 1)\n","        # Feed the convolution output into the LSTM; get the hidden states.\n","        _, (hidden, _) = self.lstm(conv_out)\n","        # Use the hidden state of the last LSTM layer for classification.\n","        return self.fc(hidden[-1])"],"metadata":{"id":"OGBBsOIANttT","executionInfo":{"status":"ok","timestamp":1743849194738,"user_tz":-480,"elapsed":1,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["**BiStackedLSTMClassifier**"],"metadata":{"id":"L3RvZFlrNv7h"}},{"cell_type":"code","source":["class BiStackedLSTMClassifier(nn.Module):\n","    \"\"\"\n","    BiStackedLSTMClassifier implements a bidirectional LSTM classifier.\n","    It applies an embedding layer followed by a bidirectional LSTM and a fully connected layer.\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx, num_layers=2):\n","        super().__init__()\n","        # Embedding layer to convert input token indices into dense vectors.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n","        # Bidirectional LSTM layer with the specified number of layers.\n","        # batch_first=True means the input shape is [batch_size, sequence_length, embedding_dim].\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=True)\n","        # Fully connected layer that maps the concatenated hidden states to the output dimension.\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","\n","    def forward(self, text):\n","        # If the input text has zero length, return a tensor of zeros with appropriate shape.\n","        if text.size(1) == 0:\n","            return torch.zeros(text.size(0), self.fc.out_features, device=text.device)\n","        # Convert input token indices into embeddings.\n","        embedded = self.embedding(text)\n","        # Pass embeddings through the bidirectional LSTM.\n","        # The output is ignored as we are only interested in the hidden states.\n","        _, (hidden, _) = self.lstm(embedded)\n","        # Concatenate the last forward and backward hidden states.\n","        hidden_cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","        # Pass the concatenated hidden states through the fully connected layer to get logits.\n","        return self.fc(hidden_cat)"],"metadata":{"id":"QruuS28vNyYk","executionInfo":{"status":"ok","timestamp":1743849194739,"user_tz":-480,"elapsed":1,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["**AttentionBiStackedLSTMClassifier**"],"metadata":{"id":"pj49bx5RN0Dr"}},{"cell_type":"code","source":["class Attention(nn.Module):\n","    \"\"\"\n","    Attention module that computes a context vector.\n","    It uses the current hidden state as the query and the encoder outputs as keys to\n","    calculate compatibility scores. The scores undergo a softmax to produce attention\n","    weights, which are then used to compute a weighted sum of the encoder outputs.\n","    \"\"\"\n","    def __init__(self, hidden_dim):\n","        super().__init__()\n","        # Linear layer to transform the query (hidden state)\n","        self.W = nn.Linear(hidden_dim, hidden_dim)\n","        # Linear layer to transform the encoder outputs (keys)\n","        self.U = nn.Linear(hidden_dim, hidden_dim)\n","        # Learnable parameter for computing the compatibility score\n","        self.v = nn.Parameter(torch.randn(hidden_dim))\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # hidden: (batch_size, hidden_dim)\n","        # encoder_outputs: (batch_size, seq_length, hidden_dim)\n","\n","        # Expand hidden to (batch_size, 1, hidden_dim) to use it as the query for attention\n","        hidden = hidden.unsqueeze(1)\n","\n","        # Compute intermediate scores by applying a tanh activation on the sum of\n","        # transformed hidden (query) and encoder outputs (keys); shape: (batch_size, seq_length, hidden_dim)\n","        score = torch.tanh(self.W(hidden) + self.U(encoder_outputs))\n","\n","        # Compute raw attention scores by taking the dot product with the learnable vector v;\n","        # resulting shape: (batch_size, seq_length)\n","        attention_weights = torch.matmul(score, self.v)\n","\n","        # Apply softmax to obtain a probability distribution over the sequence length\n","        attention_weights = F.softmax(attention_weights, dim=1)\n","\n","        # Compute the context vector as the weighted sum of encoder outputs according to the attention weights;\n","        # resulting shape: (batch_size, hidden_dim)\n","        context_vector = torch.sum(attention_weights.unsqueeze(-1) * encoder_outputs, dim=1)\n","        return context_vector"],"metadata":{"id":"s2OKZ2dWN2XG","executionInfo":{"status":"ok","timestamp":1743849195578,"user_tz":-480,"elapsed":2,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["class AttenationBiStackedLSTMClassifier(nn.Module):\n","    \"\"\"\n","    AttenationBiStackedLSTMClassifier implements a bidirectional LSTM classifier augmented with an attention mechanism.\n","    It utilizes an embedding layer, a bidirectional LSTM to capture both forward and backward context, and an attention module to combine the encoded sequence information.\n","    The resulting context vector is then passed through a fully connected layer to produce the final output for classification.\n","    \"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, padding_idx, num_layers=2):\n","        super().__init__()\n","        # Initialize the embedding layer to convert input indices to dense vectors.\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n","        # Create a bidirectional LSTM layer.\n","        # Note: This generates outputs with dimension hidden_dim * 2 due to bidirectionality.\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, num_layers=num_layers, bidirectional=True)\n","        # Fully connected layer to map the context vector from attention to the desired output dimension.\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n","        # Attention module that operates on the concatenated hidden states (from both directions).\n","        self.attention = Attention(hidden_dim * 2)\n","\n","    def forward(self, text):\n","        # Handle empty input: if the sequence length is zero, return a tensor of zeros.\n","        if text.size(1) == 0:\n","            return torch.zeros(text.size(0), self.fc.out_features, device=text.device)\n","        # Obtain embeddings from the input text.\n","        embedded = self.embedding(text)\n","\n","        # Process the embeddings through the bidirectional LSTM.\n","        # outputs: tensor of shape [batch_size, seq_length, hidden_dim*2]\n","        # hidden: tensor of shape [num_layers*2, batch_size, hidden_dim]\n","        outputs, (hidden, _) = self.lstm(embedded)\n","\n","        # Concatenate the last hidden state from the forward and backward passes.\n","        # hidden[-2, :, :] corresponds to the forward LSTM of the last layer.\n","        # hidden[-1, :, :] corresponds to the backward LSTM of the last layer.\n","        hidden_cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n","\n","        # Use the concatenated hidden state as query and the LSTM outputs as keys/values for attention.\n","        context = self.attention(hidden_cat, outputs)\n","\n","        # Map the attention context vector to the output logits.\n","        return self.fc(context)"],"metadata":{"id":"b8Zout5pN4nE","executionInfo":{"status":"ok","timestamp":1743849196829,"user_tz":-480,"elapsed":4,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, device, current_epoch, total_epochs):\n","    # Set the model to training mode\n","    model.train()\n","    epoch_loss = 0\n","\n","    # Iterate over batches in the training data\n","    for texts, labels in track(iterator, description=f\"[bold][cyan]Epoch {current_epoch}/{total_epochs}[/bold]\"):\n","        # Move the texts and labels to the specified device (CPU or GPU)\n","        texts, labels = texts.to(device), labels.to(device)\n","\n","        # Zero out gradients to prevent accumulation\n","        optimizer.zero_grad()\n","\n","        # Perform a forward pass through the model\n","        predictions = model(texts).squeeze(1)\n","\n","        # Calculate the loss between predictions and actual labels\n","        loss = criterion(predictions, labels)\n","\n","        # Perform a backward pass to compute gradients\n","        loss.backward()\n","\n","        # Update the model parameters using the computed gradients\n","        optimizer.step()\n","\n","        # Accumulate the batch loss\n","        epoch_loss += loss.item()\n","\n","    # Return the average loss for the epoch\n","    return epoch_loss / len(iterator)\n","\n","def evaluate(model, iterator, criterion, device):\n","    # This function evaluates the model's performance on the given data iterator (e.g., validation set)\n","    model.eval()\n","    epoch_loss = 0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for texts, labels in track(iterator, description=\"[bold][yellow]Validation[/bold]\"):\n","            texts, labels = texts.to(device), labels.to(device)\n","            predictions = model(texts).squeeze(1)\n","            loss = criterion(predictions, labels)\n","            epoch_loss += loss.item()\n","\n","            # Apply sigmoid to logits, round predictions, and compare with actual labels\n","            rounded_preds = torch.round(torch.sigmoid(predictions))\n","            correct += (rounded_preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    return epoch_loss / len(iterator), correct / total\n","\n","def test_best_model(model, test_loader, criterion, device, model_path=\"./models/model_best.pth\", write_path=\"./runs/test/test_results.txt\"):\n","    # Load the saved best model weights from disk.\n","    best_model_path = model_path\n","    model.load_state_dict(torch.load(best_model_path))\n","    model.to(device)\n","    model.eval()  # Set the model to evaluation mode.\n","\n","    total_loss = 0\n","    correct = 0\n","    total = 0\n","    # Evaluate the model on the test dataset.\n","    with torch.no_grad():\n","        for texts, labels in track(test_loader, description=\"[bold][yellow]Testing[/bold]\"):\n","            texts, labels = texts.to(device), labels.to(device)\n","            outputs = model(texts).squeeze(1)\n","            loss = criterion(outputs, labels)\n","            total_loss += loss.item()\n","\n","            # Convert model outputs to probabilities then round them to obtain final predictions.\n","            preds = torch.round(torch.sigmoid(outputs))\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    # Calculate average loss and accuracy.\n","    avg_loss = total_loss / len(test_loader)\n","    accuracy = correct / total\n","    print(f'Final Test Loss: {avg_loss:.4f}, Final Test Accuracy: {accuracy:.4f}')\n","\n","    # Append the test results to a file.\n","    with open(write_path, 'a') as f:\n","        f.write(f'\\nFinal Test Loss: {avg_loss:.4f}, Final Test Accuracy: {accuracy:.4f}')\n"],"metadata":{"id":"IX7FWWr3N6sI","executionInfo":{"status":"ok","timestamp":1743849197977,"user_tz":-480,"elapsed":7,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test_model = './models/lstm_model5.pth'\n","csv_path = '/content/drive/MyDrive/RNN_HW1/AI_Human.csv'\n","log_path = 'runs/lstm_experiment5'\n","best_model_path = './models/lstm_model5_best.pth'\n","final_model_path = './models/lstm_model5.pth'\n","test_model_path = './models/lstm_model5.pth'\n","write_result_path = './runs/test/test_results.txt'\n","model_folder = './models'\n","model_name = 'lstm_model5'\n","\n","\n","# Create directories if they do not exist\n","if not os.path.exists(log_path):\n","    os.makedirs(log_path)\n","\n","if not os.path.exists(model_folder):\n","    os.makedirs(model_folder)\n","\n","data_loader_factory = DataLoaderFactory(csv_path, batch_size_train=64, batch_size_val=64)\n","train_loader = data_loader_factory.train_loader\n","test_loader = data_loader_factory.test_loader\n","val_loader = data_loader_factory.val_loader\n","\n","vocab = data_loader_factory.vocab\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"UneFt6kFhSsy","executionInfo":{"status":"ok","timestamp":1743849695599,"user_tz":-480,"elapsed":56926,"user":{"displayName":"Anderson yu","userId":"01639472145408989384"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["# **switch your Classifier **\n","LSTMClassifier ConvLSTMClassifier BiStackedLSTMClassifier AttenationBiStackedLSTMClassifier"],"metadata":{"id":"_tmS-jAniShi"}},{"cell_type":"code","source":["embedding_dim = 100\n","hidden_dim = 256\n","output_dim = 1\n","num_layers = 1\n","\n","# switch your Classifier # LSTMClassifier ConvLSTMClassifier BiStackedLSTMClassifier AttenationBiStackedLSTMClassifier\n","model = LSTMClassifier(\n","    vocab_size=len(vocab),\n","    embedding_dim=embedding_dim,\n","    hidden_dim=hidden_dim,\n","    output_dim=output_dim,\n","    padding_idx=vocab['<pad>'],\n","    num_layers=num_layers\n",").to(device)\n","\n","criterion = nn.BCEWithLogitsLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters())\n","writer = SummaryWriter(log_path)\n","\n","best_acc = 0.0\n","total_epochs = 50\n","# Training loop\n","for epoch in range(1, total_epochs+1):\n","    train_loss = train(model, train_loader, optimizer, criterion, device, epoch, total_epochs)\n","    print(f'Epoch: {epoch}, Train Loss: {train_loss:.4f}')\n","\n","    test_loss, test_acc = evaluate(model, val_loader, criterion, device)\n","    print(f'Epoch: {epoch}, Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n","\n","    writer.add_scalar('Loss/Train', train_loss, epoch)\n","    writer.add_scalar('Loss/Test', test_loss, epoch)\n","    writer.add_scalar('Accuracy/Test', test_acc, epoch)\n","\n","    # Save best model based on test accuracy\n","    if test_acc > best_acc:\n","        best_acc = test_acc\n","        torch.save(model.state_dict(), best_model_path)\n","        print(f'Best model saved at epoch {epoch} with Test Acc: {test_acc:.4f}')\n","\n","    # Save model every 10 epochs with a custom name\n","    if epoch % 10 == 0:\n","        torch.save(model.state_dict(), model_folder + f'/{model_name}_{epoch}.pth')\n","        print(f'Model saved at epoch {epoch} as {model_name}_{epoch}.pth')\n","\n","writer.close()\n","\n","# Save the final model\n","torch.save(model.state_dict(), final_model_path)\n","\n","if test_model:\n","    test_best_model(model, test_loader, criterion, device, model_path=test_model_path, write_path=write_result_path)"],"metadata":{"id":"Is1YVXUmN9nE","colab":{"base_uri":"https://localhost:8080/","height":822,"referenced_widgets":["15030fd625d5437cbba78b0d752e5fcc","ae6b244fe2f24bd2976a1da9a0660223","70b46b0d6a2a459d9320b40215830efb","018e15cee8c6429c8ebb1e5ca0bde888","d8256720ed6341758ca4d30bca6ff91b","7a70e4fb2eb64e8b9926a38af5a04e70","58c3ce9991204d7fba026a70a7115450","9923578eaa9443f68adfaaaa22ce829d","234ab95283474570b06d9f390219e881","451cf0ebb10145cfb995fe247fc9668e","0d1c2cff0b514404b35ff359f404f336","3b3d1619bdf04fa4ba26dea4a3575e15","332e4c57c115439e888d6b1662b1022a","8d37d9a377a84f74a4ef3bb0e1e77114","4a758f0e3bfc4edcbbb93f94f8e1dcd8","b346499704a7429da4b7e1190744b104","5fc57bb2bd7a4ad8abd7f5e8e78fb610","3ddb6ccc8ff84acf838f1b3bfe82d2e4","4ec94d713d244977a802421855deee1a","1163bfcf863e44f39ba0d48c02644bf2","9a745cadb8c943ed93303683432cbc92","e63a2f47610b4e269095f8a0e501d2d9","67a262e6c3064aa386abb94f6d9c752c","d3d40f1d74924b8fa0754dfbaa59d6f2","bbba8f137ce344bbaf90c63407c56dda","321848a8647941fba496ca5668082430","c9b6743f5c3f4c519810e530ff0162ea","0337c9dc53484cc4bd7679f9d0862cf3","d319f2a9195744feb364214e61a33c1a","bdc2c55e9cbe4a439e31e6d623c4069e","f242125c31a040009483068e63f0c6df","42cacd68d47c42f5bcf52052511447f5","b1fe5cbcb4fa4d7eac324b59e4523e80","7d3d6120eba34b97a72d9b8ede0c2d03","c224b0f4aa224fdeac17981fb944bcee","17e15883f86d4d599c0c5eac9f64ba51","6b24e38a944949fa908c2d2c706334b3","f5e4928070bd4d81ba241c64d60fd93d","d28929bc1f9c4eec8c3c07b13216e574","ca523895b8f44e1cb6e0f49697f11334","7418e1c569cb4dac90c085c18c3be526","5e9466de8b674b80a861e1421258182e"]},"outputId":"59280b45-8a4d-4c85-e641-6f5cc2083589"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15030fd625d5437cbba78b0d752e5fcc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70b46b0d6a2a459d9320b40215830efb"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Train Loss: 0.2956\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Test Loss: 0.0245, Test Acc: 0.9924\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8256720ed6341758ca4d30bca6ff91b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 1 with Test Acc: 0.9924\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c3ce9991204d7fba026a70a7115450"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Train Loss: 0.0141\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 2, Test Loss: 0.0135, Test Acc: 0.9966\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"234ab95283474570b06d9f390219e881"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 2 with Test Acc: 0.9966\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d1c2cff0b514404b35ff359f404f336"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Train Loss: 0.0069\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 3, Test Loss: 0.0065, Test Acc: 0.9982\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332e4c57c115439e888d6b1662b1022a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 3 with Test Acc: 0.9982\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a758f0e3bfc4edcbbb93f94f8e1dcd8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Train Loss: 0.0030\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 4, Test Loss: 0.0030, Test Acc: 0.9990\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fc57bb2bd7a4ad8abd7f5e8e78fb610"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 4 with Test Acc: 0.9990\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ec94d713d244977a802421855deee1a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Train Loss: 0.0019\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a745cadb8c943ed93303683432cbc92"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 5, Test Loss: 0.0039, Test Acc: 0.9989\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a262e6c3064aa386abb94f6d9c752c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Train Loss: 0.0013\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 6, Test Loss: 0.0038, Test Acc: 0.9991\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbba8f137ce344bbaf90c63407c56dda"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 6 with Test Acc: 0.9991\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b6743f5c3f4c519810e530ff0162ea"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Train Loss: 0.0011\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d319f2a9195744feb364214e61a33c1a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 7, Test Loss: 0.0035, Test Acc: 0.9991\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f242125c31a040009483068e63f0c6df"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Train Loss: 0.0009\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1fe5cbcb4fa4d7eac324b59e4523e80"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 8, Test Loss: 0.0049, Test Acc: 0.9986\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c224b0f4aa224fdeac17981fb944bcee"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Train Loss: 0.0007\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 9, Test Loss: 0.0023, Test Acc: 0.9994\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b24e38a944949fa908c2d2c706334b3"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Best model saved at epoch 9 with Test Acc: 0.9994\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d28929bc1f9c4eec8c3c07b13216e574"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 10, Train Loss: 0.0005\n"]},{"output_type":"display_data","data":{"text/plain":[],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 10, Test Loss: 0.0036, Test Acc: 0.9992\n"]},{"output_type":"display_data","data":{"text/plain":["Output()"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7418e1c569cb4dac90c085c18c3be526"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model saved at epoch 10 as lstm_model5_10.pth\n"]}]},{"cell_type":"code","source":["test_best_model(model, test_loader, criterion, device, model_path=test_model_path, write_path=write_result_path)"],"metadata":{"id":"ftKgJUft5T1S"},"execution_count":null,"outputs":[]}]}